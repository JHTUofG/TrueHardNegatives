{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c300b03e-2a5c-4201-9266-847bc8fdfa42",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "\n",
    "* [Dataset collection](#Dataset-collection)\n",
    "* [Intialise Dataset, Storage and Model](#Intialise-Dataset,-Storage-and-Model)\n",
    "* [Build Triples](#Build-Triples)\n",
    "* [Training](#Training)\n",
    "* [Evaluating](#Evaluating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652dee62-c1e4-4973-81e4-b77b21acc2d7",
   "metadata": {},
   "source": [
    "## Dataset collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef11431-6583-497e-aff8-7899bf2d54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import collect_negatives # import the defined negative collection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2341262-08bf-4d4c-8647-b99bb6e249b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "negative_lookup = collect_negatives()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a15fdf-5bc1-4c47-83ae-792ffe7c19be",
   "metadata": {},
   "source": [
    "It will also save the collection to local data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c17599-3d2e-4fd0-a93c-17c5d1984f6c",
   "metadata": {},
   "source": [
    "### Load the saved negatives lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d15ce2-b31c-4020-bf1f-3030c1e601db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data\n",
    "\n",
    "negative_lookup = load_data('data', 'negative_lookup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31882e7c-1e66-4247-a4c2-94f17771ac8f",
   "metadata": {},
   "source": [
    "## Intialise Dataset, Storage and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dadd2801-607b-4a96-8496-131831b23677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "\n",
    "DATASET = r'msmarco-passage/train/triples-small' # From https://ir-datasets.com\n",
    "\n",
    "dataset = ir_datasets.load(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a449ee8-efd8-4cf3-a628-b66f512e7ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading time: 0:02:13.401365\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "start_time = datetime.now()\n",
    "docpairs = pd.DataFrame(dataset.docpairs_iter())\n",
    "docpairs.to_csv(f'data/docpairs.csv')\n",
    "end_time = datetime.now()\n",
    "\n",
    "print(\"Loading time: %s\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859408bb-fb42-4a11-8892-9a4ae25fcab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docpairs = pd.read_csv('data/docpairs.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08006188-a99a-467b-a8ce-dd0e29d4ce84",
   "metadata": {},
   "source": [
    "### 100k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "315a86a4-3de0-43fe-b555-a36270ba2662",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from data import sample_df\n",
    "\n",
    "new_docpairs = sample_df(docpairs, 100000, 'new_docpairs') # baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309c3bbe-158d-4a6d-8563-083aacb29482",
   "metadata": {},
   "source": [
    "### Build the true negative 100k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de4eddb-70bd-4269-8687-ac560956a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from data import true_negatives\n",
    "\n",
    "truenegative_docpairs = true_negatives(new_docpairs, negative_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b867220c-f785-4da9-9280-7f293d5b1f3e",
   "metadata": {},
   "source": [
    "### Load the saved 100k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cfade2b-75ad-4cee-8570-396c2c57ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_docpairs = load_data('data', 'new_docpairs')\n",
    "truenegative_docpairs = load_data('data', 'truenegative_docpairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4761f722-1873-4c8a-b02a-e72edc7290c6",
   "metadata": {},
   "source": [
    "## Build Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d316258-15de-42e8-a833-4331f07b709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import dataset_from_idx\n",
    "\n",
    "baseline_triples = dataset_from_idx(dataset, new_docpairs, 'baseline_triples')\n",
    "new_triples = dataset_from_idx(dataset, truenegative_docpairs, 'new_triples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5010e31-3797-404f-a160-56f04594f579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline_triples = pd.read_csv('data/baseline_triples.csv', index_col=0)\n",
    "new_triples = pd.read_csv('data/new_triples.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea4acb-5067-4ed2-b8b0-775e21d7bd2c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f05dfb6-324f-41f1-983a-616ea13f20f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jht412/anaconda3/envs/py310_20230225/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2beb4ff0e5464d23a8399971d9b7bfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i 'train.py' --dataset_name 'docpairs' --train_name 'baseline_triples' --out_dir 'model_base' --batch_size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de3281b-1c5f-4d78-9473-8d888fe16b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jht412/anaconda3/envs/py310_20230225/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e387a653c52c422a946f6aad28c41d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i 'train.py' --dataset_name 'docpairs' --train_name 'new_triples' --out_dir 'model_new' --batch_size 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695a72c-cdca-4dd8-8b01-20991678ef73",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473afa8b-6b33-436f-831e-4a9052ab4637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:42:40.901 [main] WARN org.terrier.structures.BaseCompressingMetaIndex - Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.9 GiB of memory would be required.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jht412/MSc_Project/Experiments/Experiment_1/evaluate.py:36: DeprecationWarning: specifying meta and meta_lengths in IterDictIndexer.index() is deprecated, use constructor instead\n",
      "  indexref = iter_indexer.index(msmarco_generate(), meta={'docno' : 20, 'text': 4096})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:43:12.397 [ForkJoinPool-1-worker-1] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (500080) - further warnings are suppressed\n",
      "03:53:15.007 [ForkJoinPool-1-worker-1] WARN org.terrier.structures.indexing.Indexer - Indexed 5 empty documents\n",
      "03:53:15.165 [main] WARN org.terrier.structures.BaseCompressingMetaIndex - Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.9 GiB of memory would be required.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jht412/anaconda3/envs/py310_20230225/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "monoT5: 100%|████████████████████████████| 755/755 [11:51<00:00,  1.06batches/s]\n",
      "monoT5: 100%|████████████████████████████| 755/755 [11:53<00:00,  1.06batches/s]\n"
     ]
    }
   ],
   "source": [
    "%run -i 'evaluate.py' --output_name '20230717' --batch_size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c3aa2-b883-44b4-bbb4-09ff70958251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
